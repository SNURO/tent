[23/06/27 12:31:59] [conf.py:  218]: PyTorch Version: torch=1.8.1+cu102, cuda=10.2, cudnn=7605
[23/06/27 12:31:59] [conf.py:  220]: BN:
  EPS: 1e-05
  MOM: 0.1
CKPT_DIR: ./ckpt
CORRUPTION:
  DATASET: cifar10
  NUM_EX: 10000
  SEVERITY: [5]
  TYPE: ['shot_noise', 'impulse_noise', 'defocus_blur', 'glass_blur', 'motion_blur', 'zoom_blur', 'snow', 'frost', 'fog', 'brightness', 'contrast', 'elastic_transform', 'pixelate', 'jpeg_compression']
CUDNN:
  BENCHMARK: True
DATA_DIR: /gallery_tate/wonjae.roh
DESC: 
EPOCH: 50
EXPERIMENTAL:
  LINEAR_RETRAIN: True
ITERATION: 1
LOG_DEST: tent_230627_123159.txt
LOG_TIME: 230627_123159
MODEL:
  ADAPTATION: tent
  ARCH: Hendrycks2020AugMix_WRN
  EPISODIC: False
OPTIM:
  BETA: 0.9
  DAMPENING: 0.0
  LR: 0.001
  METHOD: Adam
  MOMENTUM: 0.9
  NESTEROV: True
  STEPS: 1
  WD: 0.0
RNG_SEED: 1
SAVE_DIR: ./output
TEST:
  BATCH_SIZE: 200
[23/06/27 12:32:02] [experiment_linear_retrain.py:   36]: test-time adaptation: TENT
[23/06/27 12:32:02] [experiment_linear_retrain.py:  139]: model for adaptation: Hendrycks2020AugMixWRNNet(
  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (block1): NetworkBlock(
    (layer): Sequential(
      (0): BasicBlock(
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (convShortcut): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (1): BasicBlock(
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (2): BasicBlock(
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (3): BasicBlock(
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (4): BasicBlock(
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (5): BasicBlock(
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
  )
  (block2): NetworkBlock(
    (layer): Sequential(
      (0): BasicBlock(
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (convShortcut): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)
      )
      (1): BasicBlock(
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (2): BasicBlock(
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (3): BasicBlock(
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (4): BasicBlock(
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (5): BasicBlock(
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
  )
  (block3): NetworkBlock(
    (layer): Sequential(
      (0): BasicBlock(
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (convShortcut): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
      )
      (1): BasicBlock(
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (2): BasicBlock(
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (3): BasicBlock(
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (4): BasicBlock(
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (5): BasicBlock(
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
  )
  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
  (relu): ReLU(inplace=True)
  (fc): Linear(in_features=128, out_features=10, bias=True)
)
[23/06/27 12:32:02] [experiment_linear_retrain.py:  140]: params for adaptation: ['block1.layer.0.bn1.weight', 'block1.layer.0.bn1.bias', 'block1.layer.0.bn2.weight', 'block1.layer.0.bn2.bias', 'block1.layer.1.bn1.weight', 'block1.layer.1.bn1.bias', 'block1.layer.1.bn2.weight', 'block1.layer.1.bn2.bias', 'block1.layer.2.bn1.weight', 'block1.layer.2.bn1.bias', 'block1.layer.2.bn2.weight', 'block1.layer.2.bn2.bias', 'block1.layer.3.bn1.weight', 'block1.layer.3.bn1.bias', 'block1.layer.3.bn2.weight', 'block1.layer.3.bn2.bias', 'block1.layer.4.bn1.weight', 'block1.layer.4.bn1.bias', 'block1.layer.4.bn2.weight', 'block1.layer.4.bn2.bias', 'block1.layer.5.bn1.weight', 'block1.layer.5.bn1.bias', 'block1.layer.5.bn2.weight', 'block1.layer.5.bn2.bias', 'block2.layer.0.bn1.weight', 'block2.layer.0.bn1.bias', 'block2.layer.0.bn2.weight', 'block2.layer.0.bn2.bias', 'block2.layer.1.bn1.weight', 'block2.layer.1.bn1.bias', 'block2.layer.1.bn2.weight', 'block2.layer.1.bn2.bias', 'block2.layer.2.bn1.weight', 'block2.layer.2.bn1.bias', 'block2.layer.2.bn2.weight', 'block2.layer.2.bn2.bias', 'block2.layer.3.bn1.weight', 'block2.layer.3.bn1.bias', 'block2.layer.3.bn2.weight', 'block2.layer.3.bn2.bias', 'block2.layer.4.bn1.weight', 'block2.layer.4.bn1.bias', 'block2.layer.4.bn2.weight', 'block2.layer.4.bn2.bias', 'block2.layer.5.bn1.weight', 'block2.layer.5.bn1.bias', 'block2.layer.5.bn2.weight', 'block2.layer.5.bn2.bias', 'block3.layer.0.bn1.weight', 'block3.layer.0.bn1.bias', 'block3.layer.0.bn2.weight', 'block3.layer.0.bn2.bias', 'block3.layer.1.bn1.weight', 'block3.layer.1.bn1.bias', 'block3.layer.1.bn2.weight', 'block3.layer.1.bn2.bias', 'block3.layer.2.bn1.weight', 'block3.layer.2.bn1.bias', 'block3.layer.2.bn2.weight', 'block3.layer.2.bn2.bias', 'block3.layer.3.bn1.weight', 'block3.layer.3.bn1.bias', 'block3.layer.3.bn2.weight', 'block3.layer.3.bn2.bias', 'block3.layer.4.bn1.weight', 'block3.layer.4.bn1.bias', 'block3.layer.4.bn2.weight', 'block3.layer.4.bn2.bias', 'block3.layer.5.bn1.weight', 'block3.layer.5.bn1.bias', 'block3.layer.5.bn2.weight', 'block3.layer.5.bn2.bias', 'bn1.weight', 'bn1.bias']
[23/06/27 12:32:02] [experiment_linear_retrain.py:  141]: optimizer for adaptation: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0.0
)
[23/06/27 12:32:02] [experiment_linear_retrain.py:   48]: resetting model
[23/06/27 12:32:22] [experiment_linear_retrain.py:   76]: error % [shot_noise5]: 13.19%      20s
[23/06/27 12:32:22] [experiment_linear_retrain.py:   79]: TENT linear_finetune activated
[23/06/27 12:39:11] [experiment_linear_retrain.py:   88]: error % [shot_noise5]_finetune: 12.50%      409s
[23/06/27 12:39:11] [experiment_linear_retrain.py:   50]: not resetting model
[23/06/27 12:39:20] [experiment_linear_retrain.py:   76]: error % [impulse_noise5]: 22.30%      8s
[23/06/27 12:39:20] [experiment_linear_retrain.py:   79]: TENT linear_finetune activated
[23/06/27 12:46:12] [experiment_linear_retrain.py:   88]: error % [impulse_noise5]_finetune: 21.31%      412s
[23/06/27 12:46:12] [experiment_linear_retrain.py:   50]: not resetting model
[23/06/27 12:46:20] [experiment_linear_retrain.py:   76]: error % [defocus_blur5]: 8.95%      8s
[23/06/27 12:46:20] [experiment_linear_retrain.py:   79]: TENT linear_finetune activated
[23/06/27 12:53:13] [experiment_linear_retrain.py:   88]: error % [defocus_blur5]_finetune: 9.13%      412s
[23/06/27 12:53:13] [experiment_linear_retrain.py:   50]: not resetting model
[23/06/27 12:53:21] [experiment_linear_retrain.py:   76]: error % [glass_blur5]: 21.87%      8s
[23/06/27 12:53:21] [experiment_linear_retrain.py:   79]: TENT linear_finetune activated
[23/06/27 13:00:14] [experiment_linear_retrain.py:   88]: error % [glass_blur5]_finetune: 20.68%      413s
[23/06/27 13:00:14] [experiment_linear_retrain.py:   50]: not resetting model
[23/06/27 13:00:23] [experiment_linear_retrain.py:   76]: error % [motion_blur5]: 10.48%      8s
[23/06/27 13:00:23] [experiment_linear_retrain.py:   79]: TENT linear_finetune activated
[23/06/27 13:07:16] [experiment_linear_retrain.py:   88]: error % [motion_blur5]_finetune: 10.69%      413s
[23/06/27 13:07:16] [experiment_linear_retrain.py:   50]: not resetting model
[23/06/27 13:07:24] [experiment_linear_retrain.py:   76]: error % [zoom_blur5]: 9.69%      8s
[23/06/27 13:07:24] [experiment_linear_retrain.py:   79]: TENT linear_finetune activated
[23/06/27 13:14:17] [experiment_linear_retrain.py:   88]: error % [zoom_blur5]_finetune: 8.98%      413s
[23/06/27 13:14:17] [experiment_linear_retrain.py:   50]: not resetting model
[23/06/27 13:14:26] [experiment_linear_retrain.py:   76]: error % [snow5]: 12.81%      8s
[23/06/27 13:14:26] [experiment_linear_retrain.py:   79]: TENT linear_finetune activated
[23/06/27 13:21:19] [experiment_linear_retrain.py:   88]: error % [snow5]_finetune: 12.40%      413s
[23/06/27 13:21:19] [experiment_linear_retrain.py:   50]: not resetting model
[23/06/27 13:21:27] [experiment_linear_retrain.py:   76]: error % [frost5]: 13.32%      8s
[23/06/27 13:21:27] [experiment_linear_retrain.py:   79]: TENT linear_finetune activated
[23/06/27 13:28:20] [experiment_linear_retrain.py:   88]: error % [frost5]_finetune: 12.87%      413s
[23/06/27 13:28:20] [experiment_linear_retrain.py:   50]: not resetting model
[23/06/27 13:28:29] [experiment_linear_retrain.py:   76]: error % [fog5]: 15.01%      8s
[23/06/27 13:28:29] [experiment_linear_retrain.py:   79]: TENT linear_finetune activated
[23/06/27 13:35:22] [experiment_linear_retrain.py:   88]: error % [fog5]_finetune: 14.87%      413s
[23/06/27 13:35:22] [experiment_linear_retrain.py:   50]: not resetting model
[23/06/27 13:35:30] [experiment_linear_retrain.py:   76]: error % [brightness5]: 7.56%      8s
[23/06/27 13:35:30] [experiment_linear_retrain.py:   79]: TENT linear_finetune activated
[23/06/27 13:42:23] [experiment_linear_retrain.py:   88]: error % [brightness5]_finetune: 7.83%      413s
[23/06/27 13:42:23] [experiment_linear_retrain.py:   50]: not resetting model
[23/06/27 13:42:32] [experiment_linear_retrain.py:   76]: error % [contrast5]: 11.90%      8s
[23/06/27 13:42:32] [experiment_linear_retrain.py:   79]: TENT linear_finetune activated
[23/06/27 13:49:24] [experiment_linear_retrain.py:   88]: error % [contrast5]_finetune: 11.01%      412s
[23/06/27 13:49:24] [experiment_linear_retrain.py:   50]: not resetting model
[23/06/27 13:49:33] [experiment_linear_retrain.py:   76]: error % [elastic_transform5]: 16.33%      8s
[23/06/27 13:49:33] [experiment_linear_retrain.py:   79]: TENT linear_finetune activated
[23/06/27 13:56:25] [experiment_linear_retrain.py:   88]: error % [elastic_transform5]_finetune: 16.05%      412s
[23/06/27 13:56:25] [experiment_linear_retrain.py:   50]: not resetting model
[23/06/27 13:56:33] [experiment_linear_retrain.py:   76]: error % [pixelate5]: 14.99%      8s
[23/06/27 13:56:33] [experiment_linear_retrain.py:   79]: TENT linear_finetune activated
[23/06/27 14:03:26] [experiment_linear_retrain.py:   88]: error % [pixelate5]_finetune: 14.76%      413s
[23/06/27 14:03:26] [experiment_linear_retrain.py:   50]: not resetting model
[23/06/27 14:03:35] [experiment_linear_retrain.py:   76]: error % [jpeg_compression5]: 17.46%      8s
[23/06/27 14:03:35] [experiment_linear_retrain.py:   79]: TENT linear_finetune activated
[23/06/27 14:10:28] [experiment_linear_retrain.py:   88]: error % [jpeg_compression5]_finetune: 17.06%      413s
