[23/06/25 02:05:22] [conf.py:  216]: PyTorch Version: torch=1.8.1+cu102, cuda=10.2, cudnn=7605
[23/06/25 02:05:22] [conf.py:  218]: BN:
  EPS: 1e-05
  MOM: 0.1
CKPT_DIR: ./ckpt
CORRUPTION:
  DATASET: cifar10
  NUM_EX: 10000
  SEVERITY: [5]
  TYPE: ['gaussian_noise', 'shot_noise', 'impulse_noise', 'defocus_blur', 'glass_blur', 'motion_blur', 'zoom_blur', 'snow', 'frost', 'fog', 'brightness', 'contrast', 'elastic_transform', 'pixelate', 'jpeg_compression']
CUDNN:
  BENCHMARK: True
DATA_DIR: /gallery_tate/wonjae.roh
DESC: 
EXPERIMENTAL:
  LINEAR_RETRAIN: True
ITERATION: 1
LOG_DEST: tent_230625_020522.txt
LOG_TIME: 230625_020522
MODEL:
  ADAPTATION: tent
  ARCH: Hendrycks2020AugMix_WRN
  EPISODIC: False
OPTIM:
  BETA: 0.9
  DAMPENING: 0.0
  LR: 0.001
  METHOD: Adam
  MOMENTUM: 0.9
  NESTEROV: True
  STEPS: 1
  WD: 0.0
RNG_SEED: 1
SAVE_DIR: ./output
TEST:
  BATCH_SIZE: 200
[23/06/25 02:05:27] [experiment_linear_retrain.py:   36]: test-time adaptation: TENT
[23/06/25 02:05:27] [experiment_linear_retrain.py:  133]: model for adaptation: Hendrycks2020AugMixWRNNet(
  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (block1): NetworkBlock(
    (layer): Sequential(
      (0): BasicBlock(
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (convShortcut): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
      )
      (1): BasicBlock(
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (2): BasicBlock(
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (3): BasicBlock(
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (4): BasicBlock(
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (5): BasicBlock(
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
  )
  (block2): NetworkBlock(
    (layer): Sequential(
      (0): BasicBlock(
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (convShortcut): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)
      )
      (1): BasicBlock(
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (2): BasicBlock(
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (3): BasicBlock(
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (4): BasicBlock(
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (5): BasicBlock(
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
  )
  (block3): NetworkBlock(
    (layer): Sequential(
      (0): BasicBlock(
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (convShortcut): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
      )
      (1): BasicBlock(
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (2): BasicBlock(
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (3): BasicBlock(
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (4): BasicBlock(
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (5): BasicBlock(
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
  )
  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
  (relu): ReLU(inplace=True)
  (fc): Linear(in_features=128, out_features=10, bias=True)
)
[23/06/25 02:05:27] [experiment_linear_retrain.py:  134]: params for adaptation: ['block1.layer.0.bn1.weight', 'block1.layer.0.bn1.bias', 'block1.layer.0.bn2.weight', 'block1.layer.0.bn2.bias', 'block1.layer.1.bn1.weight', 'block1.layer.1.bn1.bias', 'block1.layer.1.bn2.weight', 'block1.layer.1.bn2.bias', 'block1.layer.2.bn1.weight', 'block1.layer.2.bn1.bias', 'block1.layer.2.bn2.weight', 'block1.layer.2.bn2.bias', 'block1.layer.3.bn1.weight', 'block1.layer.3.bn1.bias', 'block1.layer.3.bn2.weight', 'block1.layer.3.bn2.bias', 'block1.layer.4.bn1.weight', 'block1.layer.4.bn1.bias', 'block1.layer.4.bn2.weight', 'block1.layer.4.bn2.bias', 'block1.layer.5.bn1.weight', 'block1.layer.5.bn1.bias', 'block1.layer.5.bn2.weight', 'block1.layer.5.bn2.bias', 'block2.layer.0.bn1.weight', 'block2.layer.0.bn1.bias', 'block2.layer.0.bn2.weight', 'block2.layer.0.bn2.bias', 'block2.layer.1.bn1.weight', 'block2.layer.1.bn1.bias', 'block2.layer.1.bn2.weight', 'block2.layer.1.bn2.bias', 'block2.layer.2.bn1.weight', 'block2.layer.2.bn1.bias', 'block2.layer.2.bn2.weight', 'block2.layer.2.bn2.bias', 'block2.layer.3.bn1.weight', 'block2.layer.3.bn1.bias', 'block2.layer.3.bn2.weight', 'block2.layer.3.bn2.bias', 'block2.layer.4.bn1.weight', 'block2.layer.4.bn1.bias', 'block2.layer.4.bn2.weight', 'block2.layer.4.bn2.bias', 'block2.layer.5.bn1.weight', 'block2.layer.5.bn1.bias', 'block2.layer.5.bn2.weight', 'block2.layer.5.bn2.bias', 'block3.layer.0.bn1.weight', 'block3.layer.0.bn1.bias', 'block3.layer.0.bn2.weight', 'block3.layer.0.bn2.bias', 'block3.layer.1.bn1.weight', 'block3.layer.1.bn1.bias', 'block3.layer.1.bn2.weight', 'block3.layer.1.bn2.bias', 'block3.layer.2.bn1.weight', 'block3.layer.2.bn1.bias', 'block3.layer.2.bn2.weight', 'block3.layer.2.bn2.bias', 'block3.layer.3.bn1.weight', 'block3.layer.3.bn1.bias', 'block3.layer.3.bn2.weight', 'block3.layer.3.bn2.bias', 'block3.layer.4.bn1.weight', 'block3.layer.4.bn1.bias', 'block3.layer.4.bn2.weight', 'block3.layer.4.bn2.bias', 'block3.layer.5.bn1.weight', 'block3.layer.5.bn1.bias', 'block3.layer.5.bn2.weight', 'block3.layer.5.bn2.bias', 'bn1.weight', 'bn1.bias']
[23/06/25 02:05:27] [experiment_linear_retrain.py:  135]: optimizer for adaptation: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0.0
)
[23/06/25 02:05:27] [experiment_linear_retrain.py:   48]: resetting model
[23/06/25 02:05:46] [experiment_linear_retrain.py:   73]: error % [gaussian_noise5]: 15.62%      18s
[23/06/25 02:05:46] [experiment_linear_retrain.py:   76]: TENT linear_finetune activated
[23/06/25 02:18:45] [experiment_linear_retrain.py:   84]: error % [gaussian_noise5]_finetune: 3.80%      780s
[23/06/25 02:18:45] [experiment_linear_retrain.py:   50]: not resetting model
[23/06/25 02:18:53] [experiment_linear_retrain.py:   73]: error % [shot_noise5]: 16.18%      8s
[23/06/25 02:18:53] [experiment_linear_retrain.py:   76]: TENT linear_finetune activated
[23/06/25 02:31:53] [experiment_linear_retrain.py:   84]: error % [shot_noise5]_finetune: 5.74%      780s
[23/06/25 02:31:53] [experiment_linear_retrain.py:   50]: not resetting model
[23/06/25 02:32:01] [experiment_linear_retrain.py:   73]: error % [impulse_noise5]: 22.30%      8s
[23/06/25 02:32:01] [experiment_linear_retrain.py:   76]: TENT linear_finetune activated
[23/06/25 02:45:01] [experiment_linear_retrain.py:   84]: error % [impulse_noise5]_finetune: 9.64%      780s
[23/06/25 02:45:01] [experiment_linear_retrain.py:   50]: not resetting model
[23/06/25 02:45:09] [experiment_linear_retrain.py:   73]: error % [defocus_blur5]: 8.95%      8s
[23/06/25 02:45:09] [experiment_linear_retrain.py:   76]: TENT linear_finetune activated
[23/06/25 02:58:08] [experiment_linear_retrain.py:   84]: error % [defocus_blur5]_finetune: 1.66%      780s
[23/06/25 02:58:08] [experiment_linear_retrain.py:   50]: not resetting model
[23/06/25 02:58:17] [experiment_linear_retrain.py:   73]: error % [glass_blur5]: 21.87%      8s
[23/06/25 02:58:17] [experiment_linear_retrain.py:   76]: TENT linear_finetune activated
[23/06/25 03:11:16] [experiment_linear_retrain.py:   84]: error % [glass_blur5]_finetune: 9.04%      780s
[23/06/25 03:11:16] [experiment_linear_retrain.py:   50]: not resetting model
[23/06/25 03:11:24] [experiment_linear_retrain.py:   73]: error % [motion_blur5]: 10.48%      8s
[23/06/25 03:11:24] [experiment_linear_retrain.py:   76]: TENT linear_finetune activated
[23/06/25 03:24:24] [experiment_linear_retrain.py:   84]: error % [motion_blur5]_finetune: 2.27%      780s
[23/06/25 03:24:24] [experiment_linear_retrain.py:   50]: not resetting model
[23/06/25 03:24:32] [experiment_linear_retrain.py:   73]: error % [zoom_blur5]: 9.69%      8s
[23/06/25 03:24:32] [experiment_linear_retrain.py:   76]: TENT linear_finetune activated
[23/06/25 03:37:31] [experiment_linear_retrain.py:   84]: error % [zoom_blur5]_finetune: 1.73%      780s
[23/06/25 03:37:31] [experiment_linear_retrain.py:   50]: not resetting model
[23/06/25 03:37:40] [experiment_linear_retrain.py:   73]: error % [snow5]: 12.81%      8s
[23/06/25 03:37:40] [experiment_linear_retrain.py:   76]: TENT linear_finetune activated
[23/06/25 03:50:39] [experiment_linear_retrain.py:   84]: error % [snow5]_finetune: 2.98%      780s
[23/06/25 03:50:39] [experiment_linear_retrain.py:   50]: not resetting model
[23/06/25 03:50:47] [experiment_linear_retrain.py:   73]: error % [frost5]: 13.32%      8s
[23/06/25 03:50:47] [experiment_linear_retrain.py:   76]: TENT linear_finetune activated
[23/06/25 04:03:47] [experiment_linear_retrain.py:   84]: error % [frost5]_finetune: 3.83%      780s
[23/06/25 04:03:47] [experiment_linear_retrain.py:   50]: not resetting model
[23/06/25 04:03:55] [experiment_linear_retrain.py:   73]: error % [fog5]: 15.01%      8s
[23/06/25 04:03:55] [experiment_linear_retrain.py:   76]: TENT linear_finetune activated
[23/06/25 04:16:55] [experiment_linear_retrain.py:   84]: error % [fog5]_finetune: 4.97%      780s
[23/06/25 04:16:55] [experiment_linear_retrain.py:   50]: not resetting model
[23/06/25 04:17:03] [experiment_linear_retrain.py:   73]: error % [brightness5]: 7.56%      8s
[23/06/25 04:17:03] [experiment_linear_retrain.py:   76]: TENT linear_finetune activated
[23/06/25 04:30:02] [experiment_linear_retrain.py:   84]: error % [brightness5]_finetune: 1.10%      780s
[23/06/25 04:30:02] [experiment_linear_retrain.py:   50]: not resetting model
[23/06/25 04:30:10] [experiment_linear_retrain.py:   73]: error % [contrast5]: 11.90%      8s
[23/06/25 04:30:10] [experiment_linear_retrain.py:   76]: TENT linear_finetune activated
[23/06/25 04:43:10] [experiment_linear_retrain.py:   84]: error % [contrast5]_finetune: 3.48%      780s
[23/06/25 04:43:10] [experiment_linear_retrain.py:   50]: not resetting model
[23/06/25 04:43:18] [experiment_linear_retrain.py:   73]: error % [elastic_transform5]: 16.33%      8s
[23/06/25 04:43:18] [experiment_linear_retrain.py:   76]: TENT linear_finetune activated
[23/06/25 04:56:18] [experiment_linear_retrain.py:   84]: error % [elastic_transform5]_finetune: 5.44%      780s
[23/06/25 04:56:18] [experiment_linear_retrain.py:   50]: not resetting model
[23/06/25 04:56:26] [experiment_linear_retrain.py:   73]: error % [pixelate5]: 14.99%      8s
[23/06/25 04:56:26] [experiment_linear_retrain.py:   76]: TENT linear_finetune activated
[23/06/25 05:09:25] [experiment_linear_retrain.py:   84]: error % [pixelate5]_finetune: 4.27%      780s
[23/06/25 05:09:25] [experiment_linear_retrain.py:   50]: not resetting model
[23/06/25 05:09:33] [experiment_linear_retrain.py:   73]: error % [jpeg_compression5]: 17.46%      8s
[23/06/25 05:09:33] [experiment_linear_retrain.py:   76]: TENT linear_finetune activated
[23/06/25 05:22:33] [experiment_linear_retrain.py:   84]: error % [jpeg_compression5]_finetune: 6.24%      779s
